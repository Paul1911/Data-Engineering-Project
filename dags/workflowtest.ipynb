{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from helpfiles.temp_save_load import save_files, load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import helpfiles.ml_pipeline_config as configurations\n",
    "\n",
    "#Load data\n",
    "df = pd.read_csv(\"C:/Users/PC Paul/Downloads/DataEngOwnProject/data/creditcard.csv\")#.head(10000) \n",
    "while len(df.index) < 1000000:\n",
    "    df = pd.concat([df,df])\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#scale_data():\n",
    "rob_scaler = RobustScaler()\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#split_data_train_val():\n",
    "split_ratio = configurations.params['test_split_ratio']\n",
    "# Splitting\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
    "# Dataframe is concatenated again as the full dataset is needed and split again during cross validation. _val dataframes are needed for the final evaluation. \n",
    "df = pd.concat([X_train, y_train],axis = 1)\n",
    "\n",
    "#undersample_data():\n",
    "df2 = df.sample(frac=1) # this shuffles the initial df\n",
    "# Filter fraud cases and concat equal amount of non-fraud-cases\n",
    "fraud_df = df2.loc[df['Class'] == 1]\n",
    "non_fraud_df = df2.loc[df['Class'] == 0][:len(fraud_df)]\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "# Shuffle dataframe rows\n",
    "new_df = normal_distributed_df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_observation = new_df.iloc[4:5, :-1].values\n",
    "test_observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import joblib\n",
    "svc.predict(test_observation)\n",
    "\n",
    "\n",
    "now = datetime.now().strftime('%d-%m-%Y_%H-%M-%S')\n",
    "filename = 'model_' + '.pkl'\n",
    "joblib.dump(svc, filename, compress=1)\n",
    "mj = joblib.load(filename)\n",
    "mj.predict(test_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross Validation F1 score:  94.57%\n",
      "Best Parameters Logistic Regression: {'C': 10, 'penalty': 'l2'}\n",
      "Support Vector Classifier Cross Validation F1 score 94.79%\n",
      "Best Parameters SVM: {'C': 0.9, 'kernel': 'linear'}\n",
      "{'classifier': GradientBoostingClassifier(max_depth=10, n_estimators=50), 'classifier__max_depth': 10, 'classifier__n_estimators': 50}\n",
      "Recall validation result:0.9867549668874173\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "import collections\n",
    "\n",
    "# Other Libraries\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "#from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#from imblearn.under_sampling import NearMiss\n",
    "#from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime\n",
    "\n",
    "import helpfiles.ml_pipeline_config as configurations\n",
    "\n",
    "#experiment():\n",
    "X = new_df.drop('Class', axis=1)\n",
    "y = new_df['Class']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Logistic Regression \n",
    "log_reg_maxiter = configurations.params[\"logreg_maxiter\"]\n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]} #todo: put this into pipeline config\n",
    "# Grid search\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params, scoring = 'f1')\n",
    "#grid_log_reg = GridSearchCV(LogisticRegression(max_iter = log_reg_maxiter), log_reg_params) # todo: see whether you can use this line\n",
    "grid_log_reg.fit(X, y)\n",
    "# Logistic Regression estimator:\n",
    "log_reg = grid_log_reg.best_estimator_\n",
    "\n",
    "# Support Vector Classifier\n",
    "svc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']} #todo: put this into pipeline config\n",
    "# Grid search\n",
    "grid_svc = GridSearchCV(SVC(), svc_params, scoring = 'f1')\n",
    "grid_svc.fit(X, y)\n",
    "# SVC best estimator\n",
    "svc = grid_svc.best_estimator_\n",
    "\n",
    "# Evaluation\n",
    "# Logistic Regression \n",
    "log_reg_score = cross_val_score(log_reg, X, y, cv=5, scoring = 'f1')\n",
    "print('Logistic Regression Cross Validation F1 score: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')\n",
    "print(\"Best Parameters Logistic Regression: \" + str(grid_log_reg.best_params_))\n",
    "# SVC\n",
    "svc_score = cross_val_score(svc, X, y, cv=5, scoring = 'f1')\n",
    "print('Support Vector Classifier Cross Validation F1 score', round(svc_score.mean() * 100, 2).astype(str) + '%')\n",
    "print(\"Best Parameters SVM: \" + str(grid_svc.best_params_))\n",
    "\n",
    "#X_val = load_files(['X_val'])[0]\n",
    "#y_val = load_files(['y_val'])[0]\n",
    "\n",
    "#Predict Y\n",
    "y_pred_log_reg = log_reg.predict(X_val)\n",
    "y_pred_SVM = svc.predict(X_val)\n",
    "f1_log_reg = f1_score(y_val, y_pred_log_reg)\n",
    "f1_SVM = f1_score(y_val, y_pred_SVM)\n",
    "\n",
    "#******************************************************************************************************\n",
    "\n",
    "# Initialize the estimators\n",
    "log_reg_maxiter = configurations.params[\"logreg_maxiter\"]\n",
    "\n",
    "clf1 = SVC()\n",
    "clf2 = LogisticRegression(max_iter = log_reg_maxiter)\n",
    "clf3 = KNeighborsClassifier()\n",
    "clf4 = GradientBoostingClassifier()\n",
    "\n",
    "# Initialize hyperparameters for each dictionary\n",
    "\n",
    "param1 = {}\n",
    "param1['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "param1['classifier__kernel'] = ['rbf', 'poly', 'sigmoid', 'linear']\n",
    "#param1['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param1['classifier'] = [clf1]\n",
    "\n",
    "param2 = {}\n",
    "param2['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "param2['classifier__penalty'] = ['l1', 'l2']\n",
    "#param2['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param2['classifier'] = [clf2]\n",
    "\n",
    "param3 = {}\n",
    "param3['classifier__n_neighbors'] = [2,5,10,25,50]\n",
    "param3['classifier'] = [clf3]\n",
    "\n",
    "param4 = {}\n",
    "param4['classifier__n_estimators'] = [10, 50, 100, 250]\n",
    "param4['classifier__max_depth'] = [5, 10, 20]\n",
    "param4['classifier'] = [clf4]\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('classifier', clf1)])\n",
    "params = [param1, param2, param3, param4]\n",
    "\n",
    "# Train the grid search model\n",
    "gs = GridSearchCV(pipeline, params, cv=5, n_jobs=-1, scoring='recall').fit(X,y)\n",
    "print(gs.best_params_)\n",
    "\n",
    "# Predict Y\n",
    "y_pred= gs.best_estimator_.predict(X_val)\n",
    "\n",
    "# Calculate recall\n",
    "recall_val = recall_score(y_val, y_pred)\n",
    "print(\"Recall validation result:\" + str(recall_val))\n",
    "\n",
    "#******************************************************************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") #todo: globalize time stamp\n",
    "\n",
    "log_reg_results = pd.DataFrame([[\n",
    "    now,\n",
    "    'Logistic Regression',\n",
    "    grid_log_reg.best_estimator_,\n",
    "    grid_log_reg.best_params_,\n",
    "    f1_log_reg\n",
    "    ]],\n",
    "    columns = [\n",
    "        'experiment_date',\n",
    "        'method',\n",
    "        'best_estimator',\n",
    "        'best_parameters',\n",
    "        'f1_score'])\n",
    "\n",
    "svc_results = pd.DataFrame([[\n",
    "    now,\n",
    "    'Support Vector Classifier',\n",
    "    grid_svc.best_estimator_,\n",
    "    grid_svc.best_params_,\n",
    "    f1_SVM\n",
    "    ]],\n",
    "    columns = [\n",
    "        'experiment_date',\n",
    "        'method',\n",
    "        'best_estimator',\n",
    "        'best_parameters',\n",
    "        'f1_score'])\n",
    "\n",
    "results2 = pd.concat([log_reg_results,svc_results])\n",
    "\n",
    "#******************************************************************************************************\n",
    "#Creation of results table \n",
    "results = pd.DataFrame([[\n",
    "    now,\n",
    "    gs.best_params_['classifier'],\n",
    "    recall_val\n",
    "    ]],\n",
    "    columns = [\n",
    "        'experiment_date',\n",
    "        'best_estimator',\n",
    "        'recall_score'])\n",
    "\n",
    "#Creation of the dataset of evalutation metrics\n",
    "y_val_series = pd.Series(y_val)\n",
    "y_pred_series = pd.Series(y_pred)\n",
    "\n",
    "target_prediction = pd.concat([y_val.reset_index(),y_pred_series], axis = 1, ignore_index=True)\n",
    "target_prediction[0] = now\n",
    "target_prediction.columns = [\n",
    "    'experiment_date',\n",
    "    'actual_class',\n",
    "    'predicted_class']\n",
    "\n",
    "# Todo: AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADD save target prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_date</th>\n",
       "      <th>actual_class</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-10_20-28-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-10_20-28-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-10_20-28-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-10_20-28-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-10_20-28-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341764</th>\n",
       "      <td>2022-03-10_20-28-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341765</th>\n",
       "      <td>2022-03-10_20-28-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341766</th>\n",
       "      <td>2022-03-10_20-28-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341767</th>\n",
       "      <td>2022-03-10_20-28-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341768</th>\n",
       "      <td>2022-03-10_20-28-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341769 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            experiment_date  actual_class  predicted_class\n",
       "0       2022-03-10_20-28-17             0                0\n",
       "1       2022-03-10_20-28-17             0                0\n",
       "2       2022-03-10_20-28-17             0                0\n",
       "3       2022-03-10_20-28-17             0                0\n",
       "4       2022-03-10_20-28-17             0                0\n",
       "...                     ...           ...              ...\n",
       "341764  2022-03-10_20-28-17             0                0\n",
       "341765  2022-03-10_20-28-17             0                0\n",
       "341766  2022-03-10_20-28-17             0                0\n",
       "341767  2022-03-10_20-28-17             0                0\n",
       "341768  2022-03-10_20-28-17             0                0\n",
       "\n",
       "[341769 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_series = pd.Series(y_val)\n",
    "y_pred_series = pd.Series(y_pred)\n",
    "\n",
    "target_prediction = pd.concat([y_val.reset_index(),y_pred_series], axis = 1, ignore_index=True)\n",
    "target_prediction[0] = now\n",
    "target_prediction.columns = ['experiment_date','actual_class','predicted_class']\n",
    "\n",
    "#target_prediction = pd.DataFrame([[\n",
    "#    now,\n",
    "#    y_val,\n",
    "#    y_pred\n",
    "#    ]],\n",
    "#    columns = [\n",
    "#        'experiment_date',\n",
    "#        'actual_class',\n",
    "#        'predicted_class'])\n",
    "\n",
    "target_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078193    0\n",
       "1036416    0\n",
       "567866     0\n",
       "942365     0\n",
       "638911     0\n",
       "          ..\n",
       "281795     0\n",
       "945664     0\n",
       "1020521    0\n",
       "30826      0\n",
       "1079156    0\n",
       "Name: Class, Length: 341769, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall validation result: 0.9867549668874173\n",
      "precision validation result: 0.05136159944846604\n"
     ]
    }
   ],
   "source": [
    "recall_val = recall_score(y_val, y_pred)\n",
    "print(\"recall validation result: \" + str(recall_val))\n",
    "\n",
    "precision_val = precision_score(y_val, y_pred)\n",
    "print(\"precision validation result: \" + str(precision_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second try as a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the estimators\n",
    "clf1 = SVC()\n",
    "clf2 = LogisticRegression()\n",
    "clf3 = KNeighborsClassifier()\n",
    "clf4 = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize hyperparameters for each dictionary\n",
    "\n",
    "param1 = {}\n",
    "param1['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "param1['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param1['classifier'] = [clf1]\n",
    "\n",
    "param2 = {}\n",
    "param2['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "param2['classifier__penalty'] = ['l1', 'l2']\n",
    "param2['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param2['classifier'] = [clf2]\n",
    "\n",
    "param3 = {}\n",
    "param3['classifier__n_neighbors'] = [2,5,10,25,50]\n",
    "param3['classifier'] = [clf3]\n",
    "\n",
    "param4 = {}\n",
    "param4['classifier__n_estimators'] = [10, 50, 100, 250]\n",
    "param4['classifier__max_depth'] = [5, 10, 20]\n",
    "param4['classifier'] = [clf4]\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('classifier', clf1)])\n",
    "params = [param1, param2, param3, param4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.69 s\n",
      "Wall time: 44.6 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%%time\n",
    "# Train the grid search model\n",
    "gs = GridSearchCV(pipeline, params, cv=3, n_jobs=-1, scoring='roc_auc').fit(X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=250),\n",
       " 'classifier__max_depth': 5,\n",
       " 'classifier__n_estimators': 250}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9872870137837874"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_f1 = cross_val_score(gs.best_estimator_, X, y, cv=5, scoring = 'f1')\n",
    "score_f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25371527029937535"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict Y\n",
    "y_pred= gs.best_estimator_.predict(X_val)\n",
    "f1_val = f1_score(y_val, y_pred)\n",
    "f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0bc10dd72c8aaf2d861c41511aea097bfd1dfda640e26e44598e27f4cfd3593d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
